webpackJsonp([0x5f3b86cfdc22],{356:function(e,n){e.exports={data:{markdownRemark:{html:'<h1>Natural User Interfaces in het onderwijs</h1>\n<ul>\n<li>\n<p>Steven Koerts, 0904861</p>\n</li>\n<li>\n<p>Pelle Nieuwenhuizen, 0951781</p>\n</li>\n<li>\n<p>Robin Kooyman, 0958070</p>\n</li>\n<li>\n<p>Paulito de Sousa Gama, 0929470</p>\n</li>\n<li>\n<p>Docent: Anne van Brussel</p>\n</li>\n<li>\n<p>Datum: 03-06-2019</p>\n</li>\n</ul>\n<iframe width="900" height="506" src="https://www.youtube.com/embed/-yuE-86gfUE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>\n<iframe width="900" height="506" src="https://www.youtube.com/embed/Fwkh4rJ7ClY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>\n<h1>Samenvatting</h1>\n<h2>Touch user interface</h2>\n<p>Een Touch User Interface is in iedere touchscreen geïmplementeerd. De acties die men kan uitvoeren met met een Touch User Interface zijn onder andere: swipen, in- en uitzoomen, tikken en ingedrukt houden.</p>\n<p>Hoe een touch screen interface precies werkt, hangt van wat voor soort scherm wordt gebruikt. Capacitief, optisch of een resistief scherm mogen dan allemaal anders werken, ze voeren nog steeds dezelfde taak uit. Het registreren van een ‘touch’.</p>\n<p>Een touchscreen is bijna niet meer uit ons hedendaagse weg te denken. Touch User Interfaces worden bijna overal op toegepast. Smartphones, printers, consoles, etc. Alhoewel touchscreens vies kunnen worden, moeilijker leesbaar worden in klaarlichte daglicht en de schermgrootte een probleem kunnen zijn voor sommige mensen, Zijn in de loop van de jaren, touchscreens verbeterd.</p>\n<h2>Eyetracking</h2>\n<p>Het gebruik van eye-tracking als user interface is tegenwoordig nog niet erg populair. Er zijn een aantal innovatieve producten van onder andere het bedrijf Tobii die gebruik maken van zicht als natural user interface. Deze producten werken daarentegen vaak niet helemaal perfect om de gebruikelijke interfaces te vervangen. Computers die volledige integratie hebben van eye tracking zijn vaak bedoeld om mensen met communicatieve problemen te helpen.</p>\n<p>Deze apparaten maken gebruik van een aantal camera\'s en bijna infrarood licht om vast te leggen waar de gebruiker heen kijkt. Als het apparaat de positie van de ogen heeft kunnen vastleggen moet deze verwerkt worden. Deze positie samen met een aantal algoritmes en image processors worden gebruikt om te interactie met het beeldscherm te maken. Hierdoor de de gebruiker als het ware de muis op het scherm te bewegen door er naar te kijken. </p>\n<p>Hoewel eye tracking niet veel gebruikt wordt komen er steeds meer apparaten en technologieën die er gebruik van maken. In de medische kant en op het gebied van video games wordt de technologie al goed toegepast. En in de toekomst zal de technologie zich waarschijnlijk steeds meer uitbreiden. </p>\n<h2>Gestures</h2>\n<p>“Gestures” zijn al breed bekend binnen de “tech” wereld en is enorm populair onder gebruikers. Ze zijn tegenwoordig zo goed dat gebruikers niet meer doorhebben dat ze gebruik maken van deze NUI om te interacteren met de applicatie of apparaat. Denk maar aan het swipen op je telefoon, of het naar beneden scrollen op je laptop of zelfs VR.</p>\n<p>Bedrijven maken veelvuldig gebruik van deze NUI omdat het ervoor zorgt dat gebruikers intuïtief kunnen interacteren met hun applicaties of apparaten. Het brengt verschillende voordelen zoals een overzichtelijke UI en geen learning curve (als de gesture goed geïmplementeerd is). Hierdoor krijgen gebruikers een prettigere omgeving en meer plezier in het gebruiken van de applicatie of apparaat.</p>\n<p>Om “gestures” te herkennen wordt er gebruik gemaakt van verschillende camera’s en algoritmes om deze vorm van “input” om te zetten naar een actie die daarbij hoort op de applicatie of apparaat.</p>\n<p>De toekomst voor “gestures” is groot. Er zijn verschillende projecten gaande die wellicht ervoor kunnen zorgen dat je straks niet eens meer je telefoon hoeft vast te pakken om een WhatsApp berichtje te sturen met behulp van ”gestures”.</p>\n<h2>Voice recognition</h2>\n<p>Voice recognition of spraakherkenning wordt gebruikt om een informatiesysteem met de stem aan te kunnen sturen. Je kan met voice control all simple acties uitvoeren het laten opbellen van iemand, een bericht versturen of iets op laten zoeken. Voice control bestaat al langer dan we denken en komt ook onbewust voor, zo had de Windows Vista computer al een voice control optie. Ook in telefooncentrales komt het voor met automatische beantwoorders. </p>\n<p>Spraakherkenning werkt door een audiosignaal van een stem om te zetten naar een digitaal signaal. Vervolgens kan dit door middel van een spraakherkennings module worden omgezet naar een opdracht of een stuk tekst.De virtuele assistent heeft een getraind machine learning model die de commando’s aan opdrachten koppelt. Machine learning is het proces waarbij voorspellingen worden gemaakt aan de hand van een getraind model. Ditzelfde geld voor voice recognition. Aan de hand van vooraf opgenomen commando\'s kan de computer een voorspelling maken van wat er gezegd wordt. </p>\n<p>Spraakherkenning heeft een hoop toekomst het is erg handig in de auto, als je een systeem zonder handen moet bedienen. Maar het is nog niet al te nauwkeurig en het duurt nog even voordat het systeem alle commando’s honderd procent herkend.     </p>\n<h2>Motion detection</h2>\n<p>Voor motion detection wordt vooral gekeken naar input door middel van beweging van vrijwel het hele lichaam. Deze technologie is vooral populair in de videogame industrie, dit komt doordat een spel spelen met het erg interactief is voor de gebruiker. Één van de bekendste voorbeelden hiervan is de xbox kinect. Dit was een apparaat dat kon worden toegevoegd aan de xbox 360 om het lichaam te gebruiken als bediening. </p>\n<p>Deze technologie maakt gebruikt van camera\'s die in staat zijn om mensen te herkennen. Ook wordt er gebruik gemaakt van bijna infrarood licht om afstanden te meten tussen verschillende objecten. De kinect is hierdoor in staat om bewegingen die een persoon maken om te zetten in bewegingen die om het scherm gebeuren. </p>\n<p>Het gebruik van het hele lichaam om een spel te besturen was een erg interessant idee maar de kinect was niet perfect. Er waren veel problemen met het apparaat waardoor het de gebruikerservaring verminderde. Het was bijvoorbeeld vermoeiend om een aantal acties uit te voeren en daarnaast werkte bewegingen vaak niet helemaal goed. De kinect verloor al snel interesse en de technologie is niet verder uitgegroeid.\f\nInhoudsopgave\nSamenvatting\t2\nInhoudsopgave\t5\nInleiding\t6\nActuele technologieën\t8\nTouch (user) interface\t8\nEyetracking\t11\nGestures\t13\nVoice recognition\t16\nMotion detection\t20\nUsability- en gebruikerservaring\t22\nTouch (user) interface\t22\nEye tracking\t24\nGestures\t26\nVoice recognition\t27\nMotion detection\t29\nConclusie\t30\nAanbeveling\t31</p>\n<h1>Inleiding</h1>\n<p>Tegenwoordig zijn er een hoop manieren om interactie te hebben met een systeem. Naast de bekende manieren van input op een computersysteem als muis en toetsenbord, kennen we nu nog veel meer manieren om interactie te hebben met een systeem. Interactie met een systeem gaat altijd via een user interface(UI) of een grafische user interface(GUI), de interface is de manier om van buitenaf invloed te hebben op een systeem. De grafische interfaces die we nu kennen bestaan voornamelijk uit knoppen op een beeldscherm, waar je met een muis naartoe kunt bewegen.Hiermee kan aan het systeem duidelijk worden maken wat je als gebruiker wilt. </p>\n<p>Tegenwoordig hebben we ook zogeheten natural user interfaces(NUI), dit zijn moderne vernieuwende interactievormen om op een natuurlijke manier een systeem te kunnen bedienen. Omdat NUI’s nog vrij nieuw zijn kan over de definitie nog wat gediscussieerd worden. Wij hebben een natural user interface als volgt gedefinieerd:  </p>\n<p>“Een natural user interface is een design principe dat uitgaat van het menselijk lichaam als interactie, met als doel dat de user interface naadloos aansluit op het systeem, waardoor de werkelijke interface lijkt te verdwijnen.”</p>\n<p>Dit is de definitie die aangehouden zal worden gedurende dit onderzoek naar natural user interfaces. Voorbeelden van interactievormen die onder de definitie van NUI’s vallen zijn bijvoorbeeld spraakherkenning of touchscreens. Door het systeem te bedienen met je stem of je eigen vingers. </p>\n<p>Het probleem met natural user interfaces is dat het heel handig en leuk kan zijn, maar een hoop mensen weten niet wat een NUI is of hoe je het moet gebruiken. Maar is een NUI wel zo handig en bruikbaar zoals men beweert? </p>\n<p>Wat maakt het dat de gebruiker overgaat op een NUI in plaats van de alternatieve UI of GUI die mensen al gewend zijn? Dat is wat dit onderzoek onder andere gaat uitzoeken. De techniek kan wel zo vernieuwend zijn, maar als het niks toevoegt aan de gebruikerservaring zal niemand de NUI gaan gebruiken.  </p>\n<h1>Doelstelling</h1>\n<p>Dit onderzoek zal gaan over de techniek achter NUI’s en hoe we deze kunnen inzetten om leerlingen van het voortgezet onderwijs kennis te laten maken met de nieuwe technieken. Dit rapport zal de volgende vraag beantwoorden: Hoe kunnen natural user interfaces worden ingezet om leerlingen van het voortgezet onderwijs te interesseren voor de techniek en wellicht de opleiding (technische)-informatica? </p>\n<p>Verdere vragen die je bij dit onderzoek kunt stellen zijn:\nWaar wordt een NUI voor gebruikt?\nHoe werkt een NUI?\nWat zijn de verschillende toepassingen van een NUI?\nWaarom zouden studenten overstappen naar een NUI, in plaats van de gebruikelijke GUI?\nHoe bruikbaar is de NUI en hoe kun je de bruikbaarheid meten?</p>\n<p>Dit onderzoek zal gedaan worden door middel van een literatuuronderzoek waarbij voorbeelden van natural user interfaces worden onderzocht. Het onderzoek beperkt zich tot de volgende NUI’s: touch, gestures, motion, eye tracking en spraakherkenning. Hierbij zal per NUI in worden gegaan op de techniek, een toepassing van de techniek en de gebruikerservaring van de techniek. </p>\n<p>Bij de gebruikerservaring kan worden afgevraagd wat de NUI toevoegt aan het gebruik van het systeem ten opzichte van, de onder de gebruikers, wel bekende GUI.</p>\n<p>Het rapport is als volgt opgebouwd, na de inleiding volgt het hoofdstuk ‘actuele technologieën’ hier zal dieper worden ingegaan op elke techniek, hoe die werkt en een toepassing van de techniek. Het volgende hoofdstuk zal meer ingaan op de ‘usability en de gebruikerservaring’ van de techniek. Als laatste sluiten we af met een aanbeveling hoe het beste interesse kan worden gewekt door middel van natural user interfaces en een conclusie of het zin heeft om natural user interfaces in het onderwijs in te zetten. </p>\n<h2>Actuele technologieën</h2>\n<p>Hier worden nieuwe interactievormen beschreven die vallen onder de definitie van een natural user interface, zoals eerder besproken.</p>\n<h2>Touch (user) interface</h2>\n<p>Een touch user interface (TUI) is een computer wijzende technologie die is gebaseerd op het gevoel van aanraken. Hierdoor maakt een TUI het mogelijk om het in staat te stellen van het activeren van computer gebaseerde functies. Daarnaast stelt het gebruikers (denk aan hen met visuele beperkingen) ook in staat een extra laag van interactie toe te voegen gebaseerd op tactiele of braille invoer, deze techniek komt voor in touchscreens. </p>\n<p>Een touchscreen wordt als volgt gedefinieerd: “Een computerscherm dat je kan aanraken om informatie te verkrijgen, dingen te kopen, etc.” ‘Informatie verkrijgen’ en ‘dingen kopen’, wordt verwezen naar de computer gebaseerde functies die overeenkomen met onze definitie van een TUI.</p>\n<p>We kennen verschillende soorten touchscreens. Zo zijn er onder andere capacitief, surface acoustic wave, optisch en resistief. De werking van deze schermen worden hieronder besproken.</p>\n<h3>Capacitief</h3>\n<p>Een capacitief scherm is gemaakt van meerdere lagen van materialen. Dit scherm heeft als bedekking glas, dit is op zijn beurt weer bedekt met een geleidend materiaal. In de meeste gevallen is dit Indiumtinoxide (ITO), een vaste oplossing die bestaat uit indium(III)oxide en tin(IV)oxide. Wanneer er contact ontstaat met het scherm, wordt er een elektrische schok gecreëerd dat de informatie naar de touch control stuurt. Met touch control wordt verstaan datgene dat alle touch besturingen aanstuurd.</p>\n<p>Figuur 1: Capacitief scherm</p>\n<p>Optisch</p>\n<p>Figuur 1.1: Optisch scherm</p>\n<p>Een optisch scherm, maakt gebruik van optische sensoren. Zo’n optische scherm is afhankelijk van infrarood lichten. Aan de bovenkant zijn namelijk twee infrarood licht sensoren gemonteerd. Wanneer er druk wordt uitgeoefend, worden de lichten van de sensoren onderbroken en terug gereflecteerd met behulp van retro reflecterende tape naar de sensoren. Hierdoor is een schaduw ontstaan op de plek waar er druk op is uitgeoefend en kan hiermee de ‘touch’ worden gevonden.</p>\n<h1>Resistief</h1>\n<p>Figuur 1.2: Resistief scherm</p>\n<p>Zoals te zien in figuur 1.2, werkt een resistief touchscreen als volgt. Het scherm is opgedeeld in meerdere lagen. Waar boven een flexibele laag is, is er onderaan een onbuigzaam materiaal. Deze lagen worden gescheiden door zogenaamde ‘dot spacers’. Net zoals een capacitief scherm, gebruikt ook een resistief scherm ITO. Zodra er druk wordt uitgeoefend op het scherm, maakt de ITO elektrisch contact. Vervolgens worden deze gegenereerde voltages geconverteerd naar X en Y coördinaten. </p>\n<p>Wat betreft qua toepassingen van een TUI, is het haast bijna niet voor te stellen dat men hier het eerst aan denkt wanneer het woord “touch” aan de pas komt in de context omtrent technologieën. Een groot deel van onze hedendaagse technologieën beschikken al over een touchscreen. Het meest voor de hand liggende zijn de smartphones. Daarnaast hebben wij onder andere ook nog tablets, monitoren, thermostaten, horloges, printers en (handheld) consoles die over een touchscreen beschikken. Met een TUI zijn veel dingen mogelijk. Zo kan men swipen om van één scherm naar het volgende scherm te gaan, bepalen naar welk precies moment van een video (o.a. youtube) naar toe willen springen, het in- en uitzoomen van afbeeldingen, het invoeren van teksten, etc. </p>\n<h1>Eyetracking</h1>\n<p>Tobii</p>\n<p>Eye tracking wordt gebruikt om te volgen waar de pupil van een persoon naar kijkt en deze informatie te gebruiken als input. Het bedrijf Tobii doet al jaren onderzoek naar eye tracking technologie en heeft een aantal verschillende producten in dit gebied. De eye trackers van Tobii werken door een paar stappen uit te voeren. Ten eerste worden projectors gebruikt om licht dat bijna infrarood is naar de gebruiker toe te projecteren. Vervolgens wordt een camera gebruikt om de reflecties van dit licht op te vangen om foto’s te maken van de ogen. Ten slotte worden verschillende technieken zoals machine learning, image processing en mathematical algorithms gebruikt om de positie van de ogen en zicht punt te bepalen. De werking is ook de zien in   figuur 2.</p>\n<p>Figuur 2: De werking van eye tracking</p>\n<p>Tobii heeft al meerdere keren laten zien dat zij in staat zijn om apparaten te maken die kunnen worden bestuurd met zicht. Op de website van Tobii dynavox worden veel producten gemaakt voor augmentive and alternative communication (AAC). Het doel hiervan is om mensen met communicatieve problemen makkelijker te laten communiceren. Op de website zijn al een aantal producten te vinden die gebruik maken van zicht als input voor hun apparaten. Een voorbeeld van deze apparaten is de I-15+, dit product is een tablet dat met zowel touch als zicht kan worden bestuurd. De gebruiker kan op dit apparaat zicht gebruiken als een soort cursor om opties te selecteren.\nTobii heeft voor hun apparaten 3 verschillende manieren om een optie te selecteren. De eerste is door middel van knipperen, de gebruiker hoeft alleen maar te knipperen om een optie aan te klikken. Deze manier is minder goed om te gebruiken aangezien de gebruiker per ongeluk een optie kan aanklikken door natuurlijk te knipperen. Daarnaast zorgt knipperen ervoor dat je kwijtraakt waar je heen kijkt. De tweede methode is door te focussen, hierbij moet de gebruiker lang genoeg naar een punt blijven kijken. Als de gebruiker voor een aantal milliseconden kijkt naar een optie wordt deze geselecteerd. Ten slotte kan de gebruiker door middel van een knop opties selecteren. Deze manier is het snelst en het meest efficiënt doordat deze methode minder snel een verkeerde optie kan selecteren.    </p>\n<h2>Medische toepassingen</h2>\n<p>In de medische wereld wordt onderzoek gedaan om apparaten te ontwikkelen die door middel van zicht bestuurd kan worden. Deze technologie maakt onder andere gebruik van de eye tracking glasses om bij te houden waar een persoon heen aan het kijken is.\nEen arts is met deze technologie in staat om een operatie uit te voeren vanuit een andere kamer. De arts kan dan door middel van een beeldscherm en de eye tracker input leveren, deze input wordt vervolgens gebruikt door een robot in de operatiekamer gebruikt om bepaalde acties uit te voeren. Deze technologie zou ook gebruikt kunnen worden zodat een doctor meerdere acties kan uitvoeren. Een doctor zou bijvoorbeeld een operatie kunnen uitvoeren en tegelijkertijd een robot arm besturen met zijn ogen. Dit zorgt ervoor dat de doctor in staat is om meerdere acties uit te voeren zonder zijn handen vrij te hoeven maken.</p>\n<p>Ten slotte wordt de technologie ook vooral gebruikt voor het onderzoek naar menselijk gedrag om te bepalen waar mensen vaak naar kijken. Dit kan bijvoorbeeld gebruikt worden voor supermarkten om te onderzoeken waar klanten eerder naar zullen kijken. Het verzamelen van informatie door middel van eye trackers kan ook worden gebruikt om de usability van producten te testen. </p>\n<h1>Gestures</h1>\n<p>“Gestures” kennen we allemaal al vanaf we jong zijn. We gebruiken onze handen om bepaalde uitdrukkingen te verspreiden naar anderen. Een voorbeeld van een gesture is te zien in figuur 3.</p>\n<p>Figuur 3: De “Gesture” voor stoppen</p>\n<p>Maar we hebben deze “gestures” sinds we Touch hebben voor onze elektronisch apparaten. Deze “gestures” vallen onder de Touchless User Interface. Voorbeelden van andere Touchless User Interfaces zijn Eye tracking en Voice Recognition, maar die zullen in een ander hoofdstuk aan bod komen.</p>\n<p>“Gestures” kunnen komen van elk deel van het lichaam. Deze worden dan vervolgens met een camera vernomen en met behulp van algoritmes omgezet in bepaalde acties voor een elektronisch apparaat.</p>\n<p>“Gesture recognition” kan worden gezien als het begin van computers die het menselijk lichaam beginnen te begrijpen. Hierdoor wordt het gat dat er is tussen mens en machine kleiner en worden de gebruikelijke GUI’s en Text User Interfaces overbodig. Stel je maar voor dat je je muis bedient met enkel wijzen naar je beeldscherm. Op dat moment is het dus niet meer nodig om een muis te gebruiken.</p>\n<p>Op veel Elektronisch apparaten hebben we al “gestures”, deze zijn echter nog allemaal gebaseerd op “touch”. Hierbij moet je het apparaat aanraken en vervolgens direct daarop met je hand een “gesture” uitvoeren. Hierdoor vallen deze niet onder de Touchless User Interface en zullen we deze ook niet bespreken.</p>\n<p>Maar we ontwikkelen al veel apparaten waar we slechts via “touchless gestures” interacteren met onze elektrische apparaten. Denk bijvoorbeeld aan de XBOX Kinect of de PS4 VR, hierbij spreken we dan van een Touchless User Interface.</p>\n<p>We hebben dus verschillende soorten types “gestures” die vallen, of onder Touch User Interface, of onder de Touchless User Interface. Hierbij zijn de “gestures” die vallen onder Touch User Interface al verder ontwikkeld. Maar wordt het aandeel Touchless User Interfaces steeds groter. Zeker nu de tech wereld kansen ziet in deze Touchless User Interfaces.</p>\n<h2>Techniek</h2>\n<p>Er zijn verschillende soorten “gestures”, maar ze worden alleen op dezelfde manier omgezet naar instructies voor het apparaat. Het verschil zit hem vooral in de manier waarop de gebruiker het apparaat van input voorziet en hoe het algoritme deze verwerkt in de applicatie.</p>\n<p>De wijzen van input kun je indelen in 2 klassen. Dit zijn zoals eerder gezegd de Touch en Touchless User Interfaces, hierbij gaat het dus om of de gebruiker het apparaat moet aanraken of niet. </p>\n<p>Denk bijvoorbeeld aan de IPhone, om te interacteren met je IPhone moet je de IPhone aanraken en valt het dus onder de Touch klasse. Echter als je denkt aan bijvoorbeeld de Xbox Kinect, die zit in de Touchless klasse. Dit omdat er geen fysiek contact nodig is tussen de gebruiker en de Xbox.</p>\n<p>Bij beide is er dus verschil op basis van input. Maar om de input uiteindelijk te verwerken naar acties voor het apparaat wordt er bij beide gevallen gemaakt van algoritmes.</p>\n<p>De techniek werkt als volgt: een camera registreert de bewegingen die jij uitvoert en stuurt deze informatie door naar de computer. De camera komt in verschillende vormen zoals 2d, 3d en IR(“InfraRed"). Waarbij elke vorm zijn eigen doel en reden heeft om te worden toegepast.</p>\n<p>Vervolgens worden er algoritmes toegepast op de data die is verkregen door de camera.</p>\n<p>Het eerste algoritme waar gebruik van gemaakt is wordt het “error-correction algorithm” genoemd. Deze bepaald of een beweging van de gebruiker wel een bepaalde “threshold” haalt. Daarmee bekijkt het programma dus of een beweging wel echt als “input” wordt bedoeld. Een voorbeeld hiervan is als je met je hand naar rechts “swiped” of je dat dan ook echt bedoelde als “swipe gesture”.</p>\n<p>Als de computer met behulp van het “error-correction” algoritme heeft bepaald dat het om een echt beweging gaat, dan gaat hij vervolgens kijken naar welke “gesture” je hebt geuit. Dit doet hij met behulp van een tweede algoritme. Hierbij vergelijkt hij de input met de bekende “gestures” en kijkt welke is daarbij past.\nUiteindelijk als de computer klaar is met het herkennen van de “gesture” voert hij de actie uit op het apparaat dat bij de geregistreerde “gesture” hoort en heb je via “gestures” een interactie gemaakt met het apparaat.</p>\n<h2>Future Of Gestures</h2>\n<p>Zoals eerder gezegd zijn de voordelen die “gestures” met zich mee brengen, mogelijk de dood voor standaard “input devices” en zelfs Touch.</p>\n<p>Bedrijven zoals Intel, Microsoft, Apple en Elliptic Labs ontwikkelen op dit moment verschillende “Touchless User Interfaces”. Voorbeelden hiervan zijn:\nAirwriting: technologie om berichten zoals WhatsApp in de lucht te schrijven en te versturen.\neyeSight: pagina navigatie zonder het fysiek contact te maken met de applicatie.\nApple Primesense: interacteren met het apparaat via gestures die worden geregistreerd me de camera, dit is te zien in figuur 4.\nFiguur 4: Interactie via “gestures”</p>\n<h1>Voice recognition</h1>\n<p>Voice recognition of spraakherkenning wordt gebruikt om een informatiesysteem met de stem aan te kunnen sturen. De gebruiker kan dan als het ware met het systeem praten en door een serie van stemcommando\'s kan het systeem op een bepaalde manier op de gebruikersinvoer reageren. </p>\n<p>Deze NUI komt al op vrij veel apparaten voor, onder andere de smartphones van zowel Android als Apple. Je kan met voice control all simple acties uitvoeren zoals het laten opbellen van iemand, een bericht versturen of iets op laten zoeken. Dat laatste wordt vooral gebruikt door de Google Assistent van Android en Siri van Apple. Verder heb je ook al smart speakers zoals Alexa, Sonos of Cortana die aangestuurd kunnen worden met je stem. </p>\n<p>Voice control bestaat al langer dan we denken en komt ook onbewust voor, de Windows Vista computer had bijvoorbeeld al een voice control optie. Ook telefooncentrales maken gebruik van automatische beantwoorders. </p>\n<p>Er komen in de toekomst waarschijnlijk ook steeds meer apparaten die stemgestuurd zijn, in figuur 5 is de hype cycle te zien waar de virtual assistant op dit moment staat. De oplopende lijn is voor nieuwe technieken en de dalende lijn is voor technieken die langzamerhand gewoon worden gevonden. </p>\n<p>Figuur 5: Hype cycle voor Emerging Technologies\f\nHoe werkt het?</p>\n<p>Figuur 6: Werking van spraakherkenning.</p>\n<p>Spraakherkenning werkt door een audiosignaal van een stem om te zetten naar een digitaal signaal, dit kan met behulp van een microfoon. Vervolgens kan dit door middel van een spraakherkennings module worden omgezet naar een opdracht of een stuk tekst. De virtuele assistent heeft een getraind machine learning model die de commando’s aan opdrachten koppelt, dit is er om te zorgen dat de gebruiker meerdere commando’s kan geven voor één actie. Bijvoorbeeld: “Bel Piet” zal hetzelfde zijn als “Ik wil Piet bellen”. Het machine learning process werkt door het koppelen van labels aan acties en er hoeft geen 100% match te zijn om een actie te kunnen uitvoeren. </p>\n<p>Een getraind model kan een voorspelling maken van wat de gebruiker gezegd zou kunnen hebben. De computer weet dus nooit precies wat er gezegd is, maar pakt het resultaat wat het beste overeenkomt met iets wat de computer eerder heeft gehoord. Door constant gegevens van gebruikers te verzamelen zal de speech recognition steeds nauwkeuriger worden en steeds beter reageren op verschillende stemmen. </p>\n<h2>Voice recognition introductie tot machine learning</h2>\n<p>Voice recognition lijkt misschien heel erg ingewikkeld, maar met behulp van een paar simpele tools en machine learning technieken is het mogelijk om je eigen audio recognition library te bouwen. De tools die dat makkelijk maken is Tensorflow, het volgende komt ook uit een Tensorflow tutorial: <a href="https://www.tensorflow.org/tutorials/sequences/audio_recognition">https://www.tensorflow.org/tutorials/sequences/audio_recognition</a>. </p>\n<pre><code>             Figuur 7: Het TensorFlow logo\n</code></pre>\n<p>Als eerste is voor machine learning de voorbereiding van de data het belangrijkst, Tensorflow heeft 1GB aan trainingsdata gratis beschikbaar om te downloaden. Dit zijn allemaal van te voren ingesproken audio commando’s. Als je de data hebt is de volgende stap het trainen van een machine learning model. Dit wordt gedaan door alle trainingsdata vervolgens te labelen en te testen met ongelabelde data. De computer heeft wel het juiste antwoord van de testdata, maar deze wordt niet getoond aan het model. Dit is om het model te testen. Dit wordt gedaan in 18.000 stappen waarbij voor elke stap de nauwkeurigheid omhoog gaat. </p>\n<p>Validitatie is een belangrijk deel van het leerproces, hier overhoor je als het ware het model. Met de test data wordt het model gevalideerd om de nauwkeurigheid te bepalen. Dit trainen van een algoritme met de minimale hoeveelheid data duurt al gauw een aantal uren. Vervolgens kan met de nieuwe data en user input een voorspelling gemaakt worden van wat er is gezegd. </p>\n<p>Dit alles wordt gedaan door middel van een convolutional neural network, dit is een tweedimensionaal neuro netwerk dat vrij simpel is om te trainen. Audio zelf is een ééndimensionale bron kijkend naar audio spectrum. Audio is een ééndimensionale golf. De tweede dimensie het neural network is de tijd die iemand nodig heeft een woord uit te spreken. Dus een combinatie van golflengte en tijd is voldoende om een schatting te maken van wat er gezegd wordt. Als je hier ook nog toonhoogte aan zou toevoegen dan kun je ook de stemmen van verschillende personen herkennen, maar dat laten we hier buiten beschouwing.</p>\n<p>De meeste spraakherkennings applicaties moeten een constante bron van audio aanhoren om een voorspelling te maken, maar het is veel efficiënter om dit te verdelen in losse clips. Dit voorkomt ook privacy issues voor de gebruiker zodat het apparaat niet constant mee te hoeven luisteren. Verder gaat het opdelen in kortere clips ook ten goede van het stroomverbruik van een apparaat. </p>\n<h2>Huidige stand van zaken</h2>\n<p>Figuur 8: Aantal stem gestuurde opdrachten van google 2008-2016 </p>\n<p>Zoals te zien is in figuur 8 neemt het aantal stem gestuurde opdrachten naar Google flink toe, zeker in de periode tussen 2013 en 2016. Het meest opvallende is dat de meeste mensen de Google assistant gebruiken om hun moeder te bellen (vaker hun hun vader) en om naar huis te navigeren. Zeker dit laatste is een handige feature voor als je in de auto zit en geen handen vrij hebt om je navigatie in te stellen. </p>\n<p>Maar niet alleen Google heeft de voice control optie, het komt in steeds meer apparaten voor. Van auto’s tot smartphones en digitale camera’s, zo heeft tegenwoordig ook de GoPro hero 7 black een voice control optie, voor als je camera op een plek staat waar je er niet bij kunt. </p>\n<p>Zoals te zien is zijn er een hoop mogelijkheden voor voice recognition in veel verschillende apparaten. Verwachtingen zijn dat er steeds meer apparaten met een stem bediend kunnen worden, zoals het licht bedienen of misschien zelfs wel je wasmachine. </p>\n<h2>Motion detection</h2>\n<p>Kinect</p>\n<p>In de afgelopen jaren zijn er veel verschillende technologieën opgekomen die gebruik maken van motion detection als natural user interface. Motion detection maakt gebruik van bewegingen om deze te gebruiken als input voor een software of programma. Voor de definitie van motion detection in dit verslag wordt vooral bedoeld beweging van vrijwel het hele lichaam. </p>\n<p>Er zijn verschillende softwares die op verschillende manieren gebruiken van motion detection. Een gebied waar motion detection in de recente jaren veel was gebruikt was in video games, de Xbox Kinect is hier een voorbeeld van. De Kinect is ingebouwd met een camera die een driedimensionale foto maakt van objecten in zijn zicht . Vervolgens is deze in staat om een mens te herkennen tussen deze objecten. De objecten worden vastgelegd door middel van licht dat bijna infrarood is. De Kinect legt vast hoe lang het duurt voordat de lichtstralen terugkeren, hierdoor kan er berekend worden hoe ver weg objecten zijn met een nauwkeurigheid van ongeveer 1 cm. De werking is te zien in figuur 9.\nDoordat de Kinect de vorm van een mens kan herkennen is deze in staat om de houding en beweging van de persoon vast te leggen. Deze bewegingen kunnen vervolgens gebruikt worden als input voor de video game. Zo kan een personage in het spel op dezelfde manier bewogen kunnen worden als de speler waardoor het lijkt alsof de speler het personage zelf is.</p>\n<p>Figuur 9: Werking van de Xbox Kinect\nHolosuit</p>\n<p>De Holosuit is een nieuw ontwikkelde technologie die het hele lichaam kan gebruiken om input aan te nemen. Dit pak bestaat uit een aantal verschillende delen zoals een vest en handschoenen met meerdere sensoren, deze sensoren meten de bewegingen die het lichaam maken. Doordat het pak vrijwel het hele lichaam bedekt is het in staat om bijna alle bewegingen vast te leggen, van het bewegen van een been tot zowel het bewegen van de vingers.\nDe bewegingen die gemaakt worden met de Holosuit kunnen worden gebruikt om input te leveren aan verschillende apparaten. Verder kan de Holosuit gebruikt worden om acties te simuleren in een virtuele omgeving. De bewegingen die de gebruiker maakt worden dan uitgevoerd door een virtuele avatar op het scherm. Dit zorgt ervoor dat acties realistisch kunnen worden nagemaakt op een computer scherm.</p>\n<h2>Usability- en gebruikerservaring</h2>\n<p>Hier wordt dieper ingegaan op wat de gebruiker vindt van de interface, maakt de NUI het gebruik makkelijker? Is er een minimale leercurve voor de interface? En hoe vernieuwend is de nieuwe interface, of heeft de interface nog flink wat ontwikkeling nodig voordat het echt in productie kan? </p>\n<h1>Touch (user) interface</h1>\n<p>De TUI is een technologie die wij al wat langer dan vandaag kennen. Vele van ons hebben het meegemaakt toen het voor het eerst werd geïmplementeerd in smartphones. Anderen zijn er in aanraking gekomen door de nintendo ds die als eerste handheld console van hun eigen line-up, touchscreen technology heeft geïmplementeerd. In 2004-2005 maakte de Nintendo DS zijn debuut in het westen. Wat de meesten niet weten, is dat de eerste officiële touchscreen al in de jaren 70 een debuut maakte. Tegenwoordig kunnen wij ons bijna geen wereld meer in voorstellen waarin een mobiel nog gepaard gaat met een fysiek toetsenbord.</p>\n<p>De voordelen van een TUI zijn onder andere de learning curve. Voor mensen is het gebruik van een touchscreen makkelijk aan te leren. Daarnaast kan een touchscreen zoveel informatie weergeven (afhankelijk van wat de gebruiker wilt hebben) om een bepaalde taak te verwerken. Dit zorgt ervoor dat gebruikers door een heel complex proces kunnen gaan, in een hele simpele en tegelijkertijd ook een systematische manier.</p>\n<p>Dit is te zien in hoe TUI’s zijn toegepast in ons dagelijks leven. Het gebruik van een TUI is zo populair geworden door de jaren heen dat het toegepast is in publieke informatie kiosks, ticket machine op stations, elektronische stemmachines, militaire computers en andere vergelijkbare applicaties. Het gebruik van computers met schermen en keyboards zou behalve lastig, ook nog in onze huidige tijd duur zijn. Denk hierbij aan de onderhoud ervan.</p>\n<p>Daarentegen zijn de nadelen die een TUI beschikt onder andere de snelheid van het invoeren van teksten op een touchscreen in plaats van op een fysiek toetsenbord. Hoewel dit als een nadeel wordt gezien, neemt dit in de laatste jaren ook af. Met name door swipe keyboards. </p>\n<p>Met een een swipe keyboard kan men, wat de naam al zegt, teksten invoeren door middel van swipen. Door langs de letters te gaan, wordt er een woord gespeld. Dit maakt het mogelijk om sneller teksten te kunnen typen op een touch screen. </p>\n<p>Overige nadelen zijn: viezigheid, helderheid en schermgrootte.\nIn tegenstelling tot een monitor of tv, wordt een touchscreen sneller en meer vies. In klaarlichte daglicht is het moeilijker van het scherm te lezen, tenzij deze op een hogere helderheid wordt gezet. Dit heeft als gevolg dat de levensduur van de batterij lager kan uitpakken (afhankelijk van het gebruik). Gelukkig zijn er nu apparaten met een redelijk gemiddeld batterijlevensduur in verhouding tot het energiegebruik van een touchscreen. Tot slot, afhankelijk van de grootte van het scherm, kan men het gebruik van een touchscreen als onhandig ervaren. Dit is een veelvoorkomend probleem op kleinere touchscreens of mensen die wat grotere vingers hebben. Wordt het scherm groter gemaakt om dit te kunnen compenseren, dan wordt een touchscreen minder compact om mee te nemen.</p>\n<h1>Eye tracking</h1>\n<p>De meeste producten van Tobii die gebruik maken van Gaze interaction zijn vaak niet erg populair. Dit zou eventueel in verband kunnen zijn met het feit dat deze technologie vooral bedoeld is voor mensen met communicatieve problemen. Doordat deze doelgroep niet heel groot is kan er minder gevonden worden in verband met usability of user experience. Daarnaast kan het ook liggen aan dat de producten die volledig gebruik maken van deze technologie vrij duur zijn. Aangezien een apparaat meestal rond de 8000 euro kost zorgt dit ervoor dat mensen vaak een goedkoper en simpeler apparaat willen hebben. </p>\n<p>Tobii heeft daarentegen een aantal kleine producten die gebruik maken van eye tracking en deze losse apparaten kosten vaak minder geld en zijn simpeler te gebruiken. Voor het bekijken van de user experience bij Tobii producten wordt er gekeken naar een aantal reviews die zijn gegeven aan een eye tracker van Tobii.\nIn dit voorbeeld is een review van de Tobii eye tracker 4C weergegeven, dit is een klein apparaat dat kan worden aangesloten aan een computer of laptop. Het review is geschreven door Lewis Painter, hij is een Game Editor bij Tech Advisor en Macworld UK. In dit review wordt de 4C eye tracker gebruikt samen met games om de functionaliteit ervan uit te proberen. De reviewer schrijft dat de 4C eye tracker goed in staat is om de beweging van de ogen bij te houden. Zelf al heeft de gebruiker een bril op heeft of als er tegenlicht is kan de 4C de bewegingen van de ogen bijhouden. Het apparaat is daarnaast ook in staat om het hoofd van de gebruiker bij te houden. De eye tracker is in staat om samen met windows 10 de eye tracking te gebruiken als input voor een computer of laptop. Er wordt daarentegen geschreven dat de 4C niet geschikt om de gebruikelijke input te vervangen, de eye tracker is beter om de ervaring te verbeteren. De schrijver zegt daarentegen wel dat de kabel van de eye tracker te kort is. Hij zegt dat dit kan komen doordat het apparaat eigenlijk is bedoeld voor het gebruik bij laptops.</p>\n<p>Figuur 10: De Tobii 4C eye tracker\nHet volgende review over de Tobii 4C eye tracker is geschreven door Mark Hachman, een senior editor bij PCWorld. Net als bij het vorige artikel zegt de schrijver hier dat de 4C misschien net beter is dan een muis maar nog niet helemaal in staat is om de gebruikelijke interface te vervangen. Hij noemt daarentegen ook dat het apparaat beter werkt om de ervaring van een videogame te verbeteren. De conclusie die de schrijver trekt is dat de de eye tracker 4C nog niet efficiënt en goed genoeg werkt om de gebruikelijke muis te vervangen. Daarentegen wordt wel benoemd dat de eye tracker potentie toont op het gebied van gaming.</p>\n<p>Door de Tobii 4C eye tracker als voorbeeld te nemen kan de conclusie worden getrokken dat de technologie goed werkt. Gebruikers vinden dat het apparaat ogen goed kan volgen en dit relatief goed kunnen gebruiken als input. Daarentegen is deze technologie erg duur wat veel mensen kan afschrikken. Maar ondanks dat de technologie goed werkt is het nog niet efficiënt genoeg om op andere GUI’s te vervangen.</p>\n<h2>Gestures</h2>\n<p>“Gestures” kennen we dus al een tijdje en is al een tijdje in gebruik. Nu, Anno 2019, hebben bijna alle mobiele apparaten “gestures”, denk maar aan Laptops, Mobiele telefoons, Oortjes. Ze zijn niet weg te denken uit ons leven.</p>\n<p>We swipen weg op onze mobiele telefoons en dit zijn allemaal “gestures”. “Gestures” hebben zich nu al goed gevestigd binnen onze tech wereld en zijn niet meer weg te denken.  “Gestures” brengen veel gemak voor de gebruiker met betrekking tot de interactie vorm.</p>\n<p>Ten eerste zorgt een goed geïmplementeerde “gesture” ervoor dat de gebruiker intuïtief kan interacteren met de applicatie zonder dat er een tutorial of handleiding aan te pas komt. Dit zorgt ervoor dat de gebruiker plezier krijgt in het gebruiken van de applicatie.</p>\n<p>Daarnaast maakt bepaalde “input” apparaten overbodig, denk hierbij aan een muis of toetsenbord. Dit bespaart niet alleen in de kosten, maar ook in dat de gebruiker fysiek deze niet meer hoeft mee te nemen of hoeft vast te pakken.</p>\n<p>Toch is de grootste plus die “gestures” met zich meenemen is het “decluttering” van de User Interface. Geen honderd knoppen op je scherm waarbij de gebruiker geen idee heeft van wat ze en daardoor geïrriteerd raakt.</p>\n<p>Echter hebben “gestures” ook zeker nadelen. Deze komen allemaal in verschillende vormen.\nTen eerste, als een “gesture” niet goed geïmplementeerd is, kan het veel narigheid geven voor de gebruiker, of als een “gesture” niet geschikt is voor een bepaalde gebruiker. Denk aan een persoon die een handicap heeft. Het is dus van belang dat alle “gestures” voor ieder persoon goed kan worden gebruikt.</p>\n<p>Daarnaast moet de “gesture” voor het gebruik intuïtief zijn. Dit is belangrijk omdat het voor alle gebruikers duidelijk moet zijn wat de “gesture” is voor welke actie en dat die gesture hierbij past. Gebruikers willen de “gesture” namelijk niet leren. De applicatie moet intuïtief genoeg zijn dat de “gesture” eruit kan opmerken.</p>\n<h2>Voice recognition</h2>\n<p>Spraakherkenning is dus een steeds vaker voorkomende techniek, van smartphones tot speakers en van particulier gebruik tot professioneel. Door middel van slimme technieken als machine learning, artificial intelligence en big data wordt er voor gezorgt dat voice recognition steeds nauwkeuriger wordt. Dankzij voice control heeft iedereen de mogelijkheid om een eigen persoonlijke digitale assistent te hebben. Iets wat daarvoor alleen was weggelegd voor management functies. </p>\n<p>De grote voordelen van voice recognition is het heel direct kunnen communiceren met een systeem waardoor de werkelijke interface lijkt te verdwijnen. Ook scheelt het de gebruiker veel tijd doordat hij/zij direct kan zeggen wat hij/zij wil. Dat is sneller dan het opzoeken van de juiste knoppen voor dezelfde acties. </p>\n<p>Nadelen van de voice recognition is dat apparaten daardoor constant mee moeten luisteren om op actie over te gaan bij een bepaald commando. Dit kan leiden to privacy klachten bij gebruikers. Ook is het nadeel dat een apparaat op elke stem reageert zoals de GoPro Hero 7 black en de Google Assistant van Android. Op de GoPro is iedereen in staat om het commando “GoPro stop recording” aan te roepen waardoor de camera stopt met filmen, wat erg vervelend kan zijn voor de eindgebruiker. Ook bij de Google Assistant zijn er problemen met bepaalde commando’s, zo zal het systeem op elke stem reageren en ook op het commando: “Bel 112”, wat niet heel erg prettig is het voor de eindgebruiker. </p>\n<p>Apple is hier al een stap verder in met Siri, die zich aanpast aan de stem van de gebruiker. Hierdoor is een vreemd persoon niet in staat om een commando uit te voeren.</p>\n<h1>Testen</h1>\n<p>In de volgende video: <a href="https://www.youtube.com/watch?v=gNx0huL9qsQ">https://www.youtube.com/watch?v=gNx0huL9qsQ</a> is een voorbeeld van een usability test te zien van de voice recognition van Siri, Alexa en Google home. </p>\n<p>Figuur 11: Een usability test van voice recognition</p>\n<p>Het probleem wat ze onderzoeken is of de verschillende platformen ook werken met verschillende talen van verschillende landen. Ze laten een aantal testpersonen tegen de virtuele assistenten spreken in hun eigen accent en kijken of de assistent doet wat de testpersonen van het systeem vragen. Het interessantste hieraan is dat alle systemen wel iets van elke taal goed verstaan dus dat de techniek en de algoritmes al zo ver getraind zijn dat ze veel verschillende systemen kunnen herkennen.</p>\n<p>Figuur 12: Antwoordformulier van de usability test</p>\n<p>Zoals in figuur 12 te zien is zijn er een hoop voordelen van speech recognition, maar er zijn ook nog een hoop punten waarop nog doorontwikkeld kan worden. Zoals het alleen reageren op een specifieke stem. Wat erg belangrijk is wanneer er verwacht wordt dat steeds meer apparaten van deze functionaliteit gebruik zullen maken in de toekomst.</p>\n<h2>Motion detection</h2>\n<p>Hoewel motion detection als natural user interface een interessant idee is wordt het nog niet veel gebruikt. Om de eerder genoemde Xbox Kinect als voorbeeld te nemen ging deze niet altijd even goed. In 2010 was een experiment gedaan waarbij 10 personen zonder ervaring met de Kinect 3 games uitproberen. Er werd hierbij vervolgens bekeken wat zij van de Kinect vonden.</p>\n<p>Uit het onderzoek bleek dat de meeste mensen moeite hadden met de verschillende menu’s van de games. Ze vonden dat het vaak moeilijk was om opties te kiezen doordat deze bijvoorbeeld te dicht bij elkaar stonden of dat de tekst te klein was. Om in bepaalde spellen het spel te pauzeren verijsde het de speler om specifieke houdingen te maken. Dit kon vaak problemen veroorzaken doordat de beweging om de houden te maken het spel kan verstoren. Over het algemeen vonden de deelnemers dat het systeem redelijk precies werkte. Als een speler meer ervaring heeft met het systeem werkt het waarschijnlijk veel beter en is het ook makkelijker. Daarentegen vonden de deelnemers wel dat het erg veel moeite kost om bepaalde acties uit te voeren. Omdat het zoveel moeite kost om acties uit te voeren vonden ze dat gebruikelijke user interfaces zoals muis of controller makkelijker zijn om uit te voeren. Veel mensen willen niet te veel moeite doen om een simpel spel te spelen dus de motion controls kunnen erg vermoeiend zijn.</p>\n<h1>Conclusie</h1>\n<p>Het doel van het onderzoek was hoe kan je met behulp van natural user interfaces leerlingen van het voortgezet onderwijs interesseren voor techniek en wellicht de opleiding (technische)-informatica. Om dit uit te zoeken is rekening gehouden met een aantal deelvragen. Hoe werkt een NUI, waar wordt het voor gebruikt en wat zijn verschillende voorbeelden van NUI’s. Welke technieken kunnen dan gebruikt worden om andere te interesseren voor techniek., welke techniek is het meest toegankelijk. </p>\n<p>De technieken die zijn onderzocht zijn touch, eye tracking, gestures, voice en motion detection. </p>\n<p>Touch interface is van al deze technieken de meest toegankelijke, het zit tegenwoordig in elk apparaat. Van smartphones tot smartwatches, deze techniek draagt iedereen tenslotte altijd dichtbij zich. De interface is vrij simpel te gebruiken en door afbeeldingen van knoppen op het scherm te tonen herkent de gebruiker dit en voelt het aan als een interface die mensen kennen van de computer op websites en fysieke drukknoppen. </p>\n<p>Eye tracking is een techniek die met behulp van een sensor de oogbewegingen van een gebruiker kan volgen. Dit wordt onder andere veel gebruikt voor usability testen om in kaart te brengen waar de gebruiker allemaal naar kijkt. Verder is er in de medische wereld nog een toepassing om te kijken of er bij een operatie apparaten door middel van de ogen kan worden aangestuurd. Tobii is een groot bedrijf wat zich bezig houdt met eye tracking software en hardware. De producten worden wel voornamelijk voor professionele doeleinden gebruikt en dat maakt deze techniek minder toegankelijk. </p>\n<p>Gestures komen voor op een hoop apparaten, voor zowel met oog en handbewegingen zijn er gestures mogelijk om een systeem aan te sturen. De gebaren worden gekoppeld aan een bepaalde actie in het systeem. De hoeveelheid apparaten en platformen die van het gesture principe gebruik maken is vrij groot en maakt deze NUI heel toegankelijk. </p>\n<p>Voice recognition is een techniek waarbij de gebruiker als het ware tegen het systeem kan praten en met bepaalde commando’s acties kan uitvoeren. Dit is een NUI die erg vaak terugkomt en steeds vaker te zien is op onze smartphones. Voor onder andere de virtuele assistenten, het op-het-scherm-toetsenbord dat vaker gebruikt wordt door het toenemen van de nauwkeurigheid van de spraakherkenningssoftware. Doordat deze techniek ook in de smartphones zit maakt dat dit een toegankelijke techniek voor iedereen. </p>\n<p>Motion detection maakt gebruik van bewegingen die gebruikt worden als input voor een software systeem. Met apparaten als de Kinect wordt dit veel gebruikt in de game industrie waardoor het lijkt alsof je zelf in de game zit en heel direct een personage bestuurd. Omdat videogames altijd erg populair zijn en dienen als manier van ontspanning is motion detection een zeer toegankelijke NUI. \f\nAanbeveling\nConcluderend van het bovenstaande kan de volgende diagram gemaakt worden om de bruikbaarheid, toegankelijkheid en het aantal toepassingen tegen elkaar uit te zetten en zo een aanbeveling te baseren welke NUI of NUI’s het beste ingezet kunnen worden om leerlingen van het voortgezet onderwijs te interesseren voor de techniek en wellicht de opleiding (technische)-informatica. </p>\n<h2>NUI</h2>\n<p>Toepassingen\nTouch interface\nSmartphones, smartwatches, TV’s, touchscreens\nEye tracking\nHoloLens, Tobii, VR\nGestures\nVR, HoloLens, Wii, Kinect\nVoice\nSiri, Google assistant, call centers\nMotion\nKinect, VR</p>\n<p>Wat te zien is in bovenstaande tabel is dat er van de gesture NUI de meeste toepassingen zijn. Voornamelijk omdat het principe van gebaren in heel veel ander NUI’s wordt gebruikt. Gestures is dus zeker iets om aan studenten voor te lichten om ze interesseren voor de techniek. Omdat de kans groot is dat je hiermee te maken krijgt. Verder zijn er touchscreens en voice recognition die in elke smartphone zitten, deze NUI’s zijn voor (bijna) elke student beschikbaar en je kan deze dus gebruiken om je eigen apps te bouwen. Met een simpele tutorial heb je ook je eigen voice recognition library. </p>\n<p>Motion is vooral leuk om te demonstreren omdat de Kinect iets duidelijk visueels heeft om te laten zien, het daadwerkelijk aan de slag gaan met de techniek is hier een stuk moeilijker. Eyetracking is het minst aantrekkelijk omdat dit nog vrij duur is en techniek beperkt aanwezig is. Niet iedereen kan het zich veroorloven om aan de slag te gaan met hardware en de software. </p>\n<p>Kortom, als er nieuwe studenten geïnteresseerd moeten worden voor de techniek dan is een kennismaking met de techniek achter touchscreens en voice recognition aan te raden. Omdat leerlingen hier vrijwel meteen mee aan de slag kunnen.</p>',
frontmatter:{title:"Advanced Usability 2.0"}}},pathContext:{slug:"/Advanced-Usability/"}}}});
//# sourceMappingURL=path---advanced-usability-d36412ffed375f4bbc6d.js.map